import{s as w,n as h}from"../chunks/scheduler.9eabb343.js";import{S as k,i as C,g as c,s as g,h as u,C as p,c as v,k as m,a as o,f as r}from"../chunks/index.3fd3c9c8.js";import{b as y}from"../chunks/paths.d4e5d7fc.js";function _(q){let e,d=`<a href="${y}/info"><img src="/help.png"/></a>`,n,a,f=`<a href="${y}/"><img src="/home.png"/></a>`,l,s,b=`<h1>Where did this data come from?</h1> <p class="home-text">In order to demonstrate a prototype of this visualization tool, we used the CounterFact dataset 
        <a href="https://rome.baulab.info/" class="highlighted-link">(Meng et al., 2022)</a> as a starting point to get a list of entities.
        This dataset contains about 20 thousand prompts with known entities and facts about them. 
        <br/><br/>
        Previous work from <a href="https://rome.baulab.info/">Meng et al. (2022)</a> and <a href="https://arxiv.org/abs/2304.14767" class="highlighted-link">Geva et al. (2023)</a> suggests 
        that for multi-token entities, Transformer models collect factual information about entities in early layers at the last token position of that entity (e.g. early representations of 
        &quot;Wars&quot; in &quot;Star Wars&quot;). Our results show that simple linear probes trained to predict &quot;Wars&quot; from &quot;Star&quot; actually systematically fail for CounterFact 
        entities (with an accuracy of 0.4%), even though the same probes can predict regular bigrams quite reliably (&quot;is&quot; from &quot;He&quot;).
    
    <br/><br/><br/> </p><h2>Where did this plot come from?</h2> <p class="home-text">For CounterFact prompts that Llama-2 was able to answer correctly, we take the hidden representations of the <i>last</i> token for each
        entity and perform dimensionality reduction to get a 2D vector describing that hidden state&#39;s similarity to other concept hidden states, 
        resulting in the scatterplot shown on this website. Currently, the data being displayed is a tSNE plot of representations at the <i>fifth</i> layer of Llama-2. 
        Confidence scores are currently placeholders. Euclidean distance measures how far any given point is to another.</p>`;return{c(){e=c("div"),e.innerHTML=d,n=g(),a=c("div"),a.innerHTML=f,l=g(),s=c("div"),s.innerHTML=b,this.h()},l(t){e=u(t,"DIV",{class:!0,"data-svelte-h":!0}),p(e)!=="svelte-1uz5799"&&(e.innerHTML=d),n=v(t),a=u(t,"DIV",{class:!0,"data-svelte-h":!0}),p(a)!=="svelte-62ahtl"&&(a.innerHTML=f),l=v(t),s=u(t,"DIV",{class:!0,"data-svelte-h":!0}),p(s)!=="svelte-1sl9ank"&&(s.innerHTML=b),this.h()},h(){m(e,"class","help-button"),m(a,"class","home-button"),m(s,"class","pt-5 pl-20 pb-10 pr-20")},m(t,i){o(t,e,i),o(t,n,i),o(t,a,i),o(t,l,i),o(t,s,i)},p:h,i:h,o:h,d(t){t&&(r(e),r(n),r(a),r(l),r(s))}}}class T extends k{constructor(e){super(),C(this,e,null,_,w,{})}}export{T as component};
